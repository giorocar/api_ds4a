{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "This NB is supposed to be run in google colab due to our lack of GPU. It train a model and save it. You are supposed to have a train and test sequences .npy files that are built with tokenizer.py script. In variable segment you are suppose to enter a value between [GROUPS,A,B,C,D,E,F] for creating the corresponding model.h5 file. \n",
    "\n",
    "Also you are provided with a script for plotting confusion matrix and calculate precision, recall and F1 scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-R-wWZwxpcD",
    "outputId": "26e86f7c-339f-4e71-9a11-1663c52742f5"
   },
   "outputs": [],
   "source": [
    "## if you're in colab run this cell for mounting your drive and use the data in there\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GO255v121blm",
    "outputId": "e986db63-0eda-4c87-a6d0-333559305c6d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4YXVwbVxyRv"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Librerias incluidas de manera personal\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn\n",
    "\n",
    "#from unidecode import unidecode\n",
    "\n",
    "\n",
    "# Librerias incluidas por defecto en el extended case\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalMaxPooling1D, Dropout, LSTM, Conv1D, RNN  ## add as many types of layer you wanna try on. Be concient that due to size of data set, even with GPU training may take a while\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "try:\n",
    "    tf.set_random_seed(1337)                    # set the random seed for reproducibility\n",
    "except:\n",
    "    tf.random.set_seed(1337)                     # NOTE: Newer version aaof tensorflow uses tf.random.set_seed\n",
    "np.random.seed(1337)                         #       instead of tf.set_random_seed\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebL6AtW0_lho"
   },
   "outputs": [],
   "source": [
    "segment = 'GROUPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU-hABW7y4Ll"
   },
   "outputs": [],
   "source": [
    "train_sequences = np.load('/content/drive/My Drive/datos_model/train_sequences_{}.npy'.format(segment))\n",
    "\n",
    "y_train = pd.read_csv('/content/drive/My Drive/datos_model/y_train_{}.csv'.format(segment), usecols=['target'])\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z14ily2r_j-L"
   },
   "outputs": [],
   "source": [
    "## Find number of categories corresponding to last layer size.\n",
    "num_neurons = y_train.target.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dncc0YelzIep"
   },
   "outputs": [],
   "source": [
    "emb_size = len(train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hZSqf9ezL_C"
   },
   "outputs": [],
   "source": [
    "#Here model is buid. You can play with type of \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Se genera una capa para el embedding (one hot encoding)\n",
    "model.add(Embedding(20000, 256, input_length=emb_size))\n",
    "\n",
    "# Paso 03. Se generan 2 capas con 128 neuronas cada una\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "#\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(num_neurons, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYmx5CbN0J2w",
    "outputId": "99baea55-8947-4b45-8bc9-78a36d044d97"
   },
   "outputs": [],
   "source": [
    "model.fit(train_sequences, y_train, validation_split=0.2, epochs=10, batch_size = 1024,\n",
    "               callbacks=[EarlyStopping(monitor='val_accuracy', mode='auto', restore_best_weights=True, patience = 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0hlWSXUJ-ol"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.save(filepath='/content/drive/My Drive/datos_model/group_{}'.format(segment),save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XWhuonPtYmu"
   },
   "outputs": [],
   "source": [
    "# If you don't have a massive ram you should restart your kernel and just \n",
    "model = tf.keras.models.load_model('/content/drive/My Drive/datos_model/group_{}.h5'.format(segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "y_test = pd.read_csv('/content/drive/My Drive/datos_model/y_test_{}.csv'.format(segment), usecols=['target'])\n",
    "test_sequences = np.load('/content/drive/My Drive/datos_model/test_sequences_{}.npy'.format(segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "Bc-TJEDp8rnR",
    "outputId": "10b9cec5-4858-4944-e9d8-483bf3184f47"
   },
   "outputs": [],
   "source": [
    "# Generemos la predicci贸n del modelo para nuestro conjunto de test\n",
    "y_predict = model.predict_classes(test_sequences) ## This may not work in futures versions of tensor flow, just use np.argmax(model.predict(test_sequences), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64ql7hDjR_OP"
   },
   "outputs": [],
   "source": [
    "# Crea la matriz de confusi贸n\n",
    "conf_mat = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7fpTfjNSF3Q"
   },
   "outputs": [],
   "source": [
    "# Valores para normalizar la matriz respecto a la cantidad de valores reales\n",
    "number_y_real = np.array([int((y_test == val).sum()) for val in sorted(y_test.target.unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xB73xVxRSMOB"
   },
   "outputs": [],
   "source": [
    "## crea la matriz de confusion normalizada\n",
    "conf_matrix = []\n",
    "for i, val in enumerate(number_y_real):\n",
    "    conf_matrix.append(conf_mat[i]/val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "Dpo1gqyDSOvc",
    "outputId": "8cae87be-608b-4ece-aea3-1a6ec2c05791"
   },
   "outputs": [],
   "source": [
    "# Plots normalized confusion matrix\n",
    "# Grafiquemos la matriz de confusi贸n normalizada en un heatmap para identificar \n",
    "# de manera mas clara donde se focalizan los aciertos y donde los errores\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\".2f\",  cmap=\"Blues\")\n",
    "plt.ylabel('100% rial no fake')\n",
    "plt.xlabel('pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "SkLgEPab8r4j",
    "outputId": "9aa276e9-43ed-443c-d9c0-9d9540c089dc"
   },
   "outputs": [],
   "source": [
    "# Grafiquemos la matriz de confusi贸n en un heatmap para identificar \n",
    "# de manera mas clara donde se focalizan los aciertos y donde los errores\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_matrix(y_test, y_predict), annot=True, fmt=\"d\",  cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7oF4zHH8sCW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlmM5wFe02a-",
    "outputId": "9a876779-8df0-4537-eb8a-c8a0f53b3f75"
   },
   "outputs": [],
   "source": [
    "# Presition, recall and F1 score table.\n",
    "print('accuracy %s' % accuracy_score(y_predict, y_test))\n",
    "print(classification_report(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIF19dMhN0vC"
   },
   "outputs": [],
   "source": [
    "model_group = tf.keras.models.load_model('/content/drive/My Drive/datos_model/group_groups.h5')\n",
    "model_b = tf.keras.models.load_model('/content/drive/My Drive/datos_model/group_B.h5')\n",
    "model_c = tf.keras.models.load_model('/content/drive/My Drive/datos_model/group_C.h5')\n",
    "model_d = tf.keras.models.load_model('/content/drive/My Drive/datos_model/group_D.h5')\n",
    "model_e = tf.keras.models.load_model('/content/drive/My Drive/datos_model/group_E.h5')\n",
    "model_f = tf.keras.models.load_model('/content/drive/My Drive/datos_model/group_F.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvfWxfU_bLSc",
    "outputId": "7f07ce03-431e-49bc-badd-85bfda47d638"
   },
   "outputs": [],
   "source": [
    "##pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKoaYEB1albI"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQOAveVAbIfk"
   },
   "outputs": [],
   "source": [
    "## If you are in collab this may take longer than the permitted time by google (~12h) if you dont have a GPU this may last also forever (LOL) try changing parameters\n",
    "## Keras-turner is a hyper-parameter searcher for keras.\n",
    "def tune_nn_model(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dense(units=128,\n",
    "\n",
    "                                 activation=\"relu\"))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        \n",
    "\n",
    "        units = hp.Int(\n",
    "\n",
    "          'units_' + str(i),\n",
    "\n",
    "          min_value=8,\n",
    "\n",
    "          max_value=64,\n",
    "\n",
    "          step=8\n",
    "\n",
    "      )\n",
    "        \n",
    "\n",
    "        model.add(keras.layers.Dense(units=units, activation='relu'))\n",
    "\n",
    "        drop_rate = hp.Choice('drop_rate_' + str(i),\n",
    "\n",
    "                            [\n",
    "\n",
    "                              0.0, 0.1, 0.2, 0.3, 0.4,\n",
    "\n",
    "                              0.5, 0.6, 0.7, 0.8, 0.9\n",
    "\n",
    "                            ])\n",
    "\n",
    "        model.add(keras.layers.Dropout(rate=drop_rate))\n",
    "\n",
    "    model.add(keras.layers.Dense(7, activation='sigmoid'))\n",
    "USDUSD\n",
    "    model.compile(\n",
    "\n",
    "        optimizer=\"adam\",\n",
    "\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "\n",
    "        metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1aH2Vz2bPFI"
   },
   "outputs": [],
   "source": [
    "MAX_TRIALS = 15\n",
    "\n",
    "EXECUTIONS_PER_TRIAL = 5\n",
    "\n",
    "tuner = RandomSearch(\n",
    "\n",
    "    tune_nn_model,\n",
    "\n",
    "    objective='val_accuracy',\n",
    "\n",
    "    max_trials=MAX_TRIALS,\n",
    "\n",
    "    executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zwboWMt6bRZf",
    "outputId": "f8fad368-efd8-4a8e-97c5-f82eebbded37"
   },
   "outputs": [],
   "source": [
    "TRAIN_EPOCHS = 15\n",
    "\n",
    "tuner.search(x=train_sequences,\n",
    "\n",
    "             y=y_train,\n",
    "\n",
    "             epochs=TRAIN_EPOCHS,\n",
    "\n",
    "             validation_data=(test_sequences, y_test),\n",
    "             batch_size = 1024,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nWERzXBcJdg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
